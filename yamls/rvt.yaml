model:
  name: "RVT"
  params:
    depth: 1
    num_heads: 2
    mlp_ratio: 4.0
    drop_rate: 0.1
    num_classes: 10
    head_bias: False
    patch_embedding:
      type: "NaivePatchEmbedding"
      params:
        patch_size: 2
        in_channels: 1
        embed_dim: 192
    positional_encoding:
      type: "Fixed2DPositionalEmbedding"
      params:
        additive: True
        img_size: (28, 28)
        requires_grad: False
        #todo Hacer que IMG_size de dataset y positional calzen

optimizer:
  name: "AdamW"
  params:
    lr: 0.001
    weight_decay: 0.01

training:
  num_epochs: 2
  loss: "cross entropy"

dataset:
  name: "MNIST"
  img_size: (1, 28, 28)
  num_classes: 10
