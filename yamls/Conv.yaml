model:
  name: "BreguiT"
  params:
    depth: 1
    num_heads: 4
    mlp_ratio: 4.0
    drop_rate: 0.2
    num_classes: 10
    head_bias: False
    patch_embedding:
      type: "NaivePatchEmbedding"
      params:
        patch_size: 2
        in_channels: 3
        embed_dim: 192
    positional_encoding:
      type: "Fixed2DPositionalEmbedding"
      params:
        additive: True
        img_size: (32, 32)
        requires_grad: True
        #todo Hacer que IMG_size de dataset y positional calzen

optimizer:
  name: "AdamW"
  params:
    lr: 0.001
    weight_decay: 0.01

training:
  num_epochs: 3
  loss: "cross entropy"

dataset:
  name: "CIFAR10"
  img_size: (3, 32, 32)
  num_classes: 10
