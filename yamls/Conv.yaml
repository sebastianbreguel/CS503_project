model:
  name: "BreguiT"
  params:
    depth: 2
    num_heads: 6
    mlp_ratio: 6.0
    drop_rate: 0.0
    num_classes: 10
    head_bias: False
    patch_embedding:
      type: "ConvEmbedding"
      params:
        patch_size: 2
        in_channels: 1
        embed_dim: 256
        out_channels: 192
    positional_encoding:
      type: "Fixed2DPositionalEmbedding"
      params:
        additive: True
        img_size: (28, 28)
        requires_grad: True
        #todo Hacer que IMG_size de dataset y positional calzen

optimizer:
  name: "AdamW"
  params:
    lr: 0.001
    weight_decay: 0.01

training:
  num_epochs: 2
  loss: "cross entropy"

dataset:
  name: "MNIST"
  img_size: (1, 28, 28)
  num_classes: 10
